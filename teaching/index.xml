<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Manling Li</title>
    <link>https://limanling.github.io/teaching/</link>
      <atom:link href="https://limanling.github.io/teaching/index.xml" rel="self" type="application/rss+xml" />
    <description>Manling Li</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 06 Mar 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://limanling.github.io/media/icon_hu127f241f63a982cda73a1c1b15888e16_9623_512x512_fill_lanczos_center_3.png</url>
      <title>Manling Li</title>
      <link>https://limanling.github.io/teaching/</link>
    </image>
    
    <item>
      <title>CS 496 Agent AI</title>
      <link>https://limanling.github.io/teaching/cs496-agent-ai/</link>
      <pubDate>Thu, 06 Mar 2025 00:00:00 +0000</pubDate>
      <guid>https://limanling.github.io/teaching/cs496-agent-ai/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: Monday 2:00pm-4:50pm, Apr 1-Jun 7, 2025 &lt;br&gt;
&lt;strong&gt;Location&lt;/strong&gt;: Technological Institute L160, Over zoom for some external talks, project presentations and discussions &lt;br&gt;
&lt;strong&gt;Instructor&lt;/strong&gt;: Prof. Manling Li (Email: &lt;a href=&#34;mailto:manling.li@northwestern.edu&#34;&gt;manling.li@northwestern.edu&lt;/a&gt;)  &lt;br&gt;
&lt;strong&gt;TA&lt;/strong&gt;: Jiahao Yu (Email: &lt;a href=&#34;mailto:jiahao.yu@northwestern.edu&#34;&gt;jiahao.yu@northwestern.edu&lt;/a&gt;)  &lt;br&gt;
&lt;strong&gt;Instructor and TA Office Hours&lt;/strong&gt;:  Instructor office hour is on Monday 9:00am-10:00am (in-person), may change to zoom due to travel schedules. TA office hours are on Monday and Wednesday over zoom (Please contact TA &lt;a href=&#34;mailto:jiahao.yu@northwestern.edu&#34;&gt;jiahao.yu@northwestern.edu&lt;/a&gt; about it)  &lt;br&gt;
&lt;strong&gt;Course Google Folder&lt;/strong&gt;: announced on Canvas.  &lt;br&gt;
&lt;strong&gt;Assignment Submission&lt;/strong&gt;: on Canvas: &lt;a href=&#34;https://canvas.northwestern.edu/courses/230363&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://canvas.northwestern.edu/courses/230363&lt;/a&gt;   &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Course Summary&lt;/strong&gt;:
This comprehensive course explores two major categories of AI agents: web-based agents that interact with digital environments and embodied agents that operate in physical spaces. Students will learn to design and implement both types of agents, understanding their unique challenges and capabilities, while mastering the integration of LLMs with various interaction modalities.
Prerequisites&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to Machine Learning&lt;/li&gt;
&lt;li&gt;Python Programming&lt;/li&gt;
&lt;li&gt;Basic Robotics or Computer Vision&lt;/li&gt;
&lt;li&gt;Linear Algebra&lt;/li&gt;
&lt;li&gt;Probability and Statistics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Students who complete this course will be able to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Design web agents that navigate digital environments&lt;/li&gt;
&lt;li&gt;Design embodied agents for physical interaction&lt;/li&gt;
&lt;li&gt;Create robust perception and action systems&lt;/li&gt;
&lt;li&gt;Control decision&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Course Syllabus&lt;/strong&gt;:&lt;/p&gt;
&lt;table border=&#34;1&#34;&gt;
    &lt;tr&gt;
        &lt;th&gt;Week&lt;/th&gt;
        &lt;th&gt;Topic&lt;/th&gt;
        &lt;th&gt;Details&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 1&lt;/td&gt;
        &lt;td&gt;Introduction to Agent AI (based on MDP)&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Definition and Overview of Agents&lt;/li&gt;
                &lt;li&gt;Markov Decision Process (MDP)&lt;/li&gt;
                &lt;li&gt;Agent Formulation based on MDP&lt;/li&gt;
                &lt;li&gt;Role of Large Language Models (LLMs)&lt;/li&gt;
                &lt;ul&gt;
                    &lt;li&gt;Goal Interpretation&lt;/li&gt;
                    &lt;li&gt;State Estimation&lt;/li&gt;
                    &lt;li&gt;MDP Policy&lt;/li&gt;
                    &lt;li&gt;Reward Modeling&lt;/li&gt;
                    &lt;li&gt;World Modeling&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 2&lt;/td&gt;
        &lt;td&gt;LLM Agent&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Agent Architectures&lt;/li&gt;
                &lt;li&gt;Self-supervised Finetuning&lt;/li&gt;
                &lt;li&gt;Reinforcement learning in agent control.&lt;/li&gt;
                &lt;li&gt;Inference Time Scaling for agents.&lt;/li&gt;
                &lt;li&gt;LLMs in Agent Learning&lt;/li&gt;
                &lt;ul&gt;
                    &lt;li&gt;Agent - Memory&lt;/li&gt;
                    &lt;li&gt;Agent - Tools&lt;/li&gt;
                    &lt;li&gt;Agent - Planning&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 3&lt;/td&gt;
        &lt;td&gt;Reasoning and Planning in Agent Models&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Introduction to Reinforcement Learning (Version 0, 1, 2, 3, 4)&lt;/li&gt;
                &lt;li&gt;PPO&lt;/li&gt;
                &lt;li&gt;DPO&lt;/li&gt;
                &lt;li&gt;GRPO&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 4&lt;/td&gt;
        &lt;td&gt;Benchmarking and Evaluation&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Evaluation Metrics: Task performance, generalization, and safety.&lt;/li&gt;
                &lt;li&gt;Ethical considerations in agent evaluation.&lt;/li&gt;
                &lt;li&gt;Benchmark Datasets and Tasks&lt;/li&gt;
                &lt;ul&gt;
                    &lt;li&gt;Web agent benchmarks: WebArena, WebGPT, CrawlBot.&lt;/li&gt;
                    &lt;li&gt;Embodied benchmarks: BEHAVIOR, Habitat, ALFRED.&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 5&lt;/td&gt;
        &lt;td&gt;Web Agents&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Web-Based Environments for Agents: HTML, APIs, and web crawling.&lt;/li&gt;
                &lt;li&gt;Examples of Web Agents&lt;/li&gt;
                &lt;li&gt;LLMs in Web Agents&lt;/li&gt;
                &lt;ul&gt;
                    &lt;li&gt;Context understanding and dialogue generation.&lt;/li&gt;
                    &lt;li&gt;Fine-tuning LLMs for domain-specific agents.&lt;/li&gt;
                    &lt;li&gt;Challenges: Multimodal web understanding.&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 6&lt;/td&gt;
        &lt;td&gt;Embodied Agents&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Foundations of Embodied Intelligence: What defines an embodied agent?&lt;/li&gt;
                &lt;li&gt;Simulated Environments: OpenAI Gym, Habitat, BEHAVIOR, MuJoCo.&lt;/li&gt;
                &lt;li&gt;Tasks for embodied agents (navigation, manipulation).&lt;/li&gt;
                &lt;li&gt;Examples of Embodied Agents: Human-robot interaction; Autonomous driving and drones.&lt;/li&gt;
                &lt;li&gt;LLMs in Embodied Agents&lt;/li&gt;
                &lt;ul&gt;
                    &lt;li&gt;Embedding reasoning and planning into embodied systems.&lt;/li&gt;
                    &lt;li&gt;Hierarchical decision-making with LLMs.&lt;/li&gt;
                    &lt;li&gt;Challenges: Grounding language in physical environments.&lt;/li&gt;
                &lt;/ul&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 7&lt;/td&gt;
        &lt;td&gt;Embodied Agents Advanced Topics&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Diffusion Models&lt;/li&gt;
                &lt;li&gt;Vision-Language-Action Models&lt;/li&gt;
                &lt;li&gt;Large World Models&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 8&lt;/td&gt;
        &lt;td&gt;Multi-Agent Systems&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Multi-agent collaboration and negotiation.&lt;/li&gt;
                &lt;li&gt;Emergent behavior in multi-agent settings.&lt;/li&gt;
                &lt;li&gt;Multi-Agent Planning&lt;/li&gt;
                &lt;ul&gt;
                    &lt;li&gt;Task allocation and shared planning.&lt;/li&gt;
                    &lt;li&gt;Auction-based and distributed algorithms.&lt;/li&gt;
                &lt;/ul&gt;
                &lt;li&gt;Examples: Swarm robotics, multi-user web agents.&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 9&lt;/td&gt;
        &lt;td&gt;Ethics and Safety in Agent AI&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Bias in agent decision-making.&lt;/li&gt;
                &lt;li&gt;Social Norms in Agent AI&lt;/li&gt;
                &lt;li&gt;Trustworthiness: Ensuring transparency and accountability.&lt;/li&gt;
                &lt;li&gt;Scaling agents for real-world applications.&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt;Week 10&lt;/td&gt;
        &lt;td&gt;Final Project Presentations&lt;/td&gt;
        &lt;td&gt;
            &lt;ul&gt;
                &lt;li&gt;Building a web agent with LLM integration.&lt;/li&gt;
                &lt;li&gt;Creating embodied agents in simulated environments.&lt;/li&gt;
                &lt;li&gt;Evaluate agent performance using real-world scenarios.&lt;/li&gt;
            &lt;/ul&gt;
        &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Grading&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Weekly Reading
&lt;ul&gt;
&lt;li&gt;20pts in total&lt;/li&gt;
&lt;li&gt;Submit a paragraph for one paper each week.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Mid-Term Exams
&lt;ul&gt;
&lt;li&gt;30pts in total&lt;/li&gt;
&lt;li&gt;Openbook exam, about open-end questions regarding three papers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Term Project
&lt;ul&gt;
&lt;li&gt;50 pts in total, 8pts project proposal (5pts report, 3pts lightning talk), 12pts mid-term project report (8pts report, 4pts milestone presentation), 30pts final project report (20pts report, 10pts presentation).&lt;/li&gt;
&lt;li&gt;The instructor will give 10 topics for the students to choose from. Students are expected to do self-teaming and each team should consist of 3-6 students. Everyone is encouraged to submit papers based on the term projects. Project score will by default be the same for all team members, but some team members can get a higher or lower score than the team score based on individual performance that is assessed in two ways: (1) checking contribution to final deliverables (e.g., Git commits and Final Project Report), and (2) Instructor and TAs&amp;rsquo; opinion from project presentations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>CS 396 Reasoning and Planning in the Foundation Model Era</title>
      <link>https://limanling.github.io/teaching/cs396-reasoning-planning/</link>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://limanling.github.io/teaching/cs396-reasoning-planning/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Time&lt;/strong&gt;: Monday and Wednesday 9:30am-10:50am &lt;br&gt;
&lt;strong&gt;Location&lt;/strong&gt;: Technological Institute M164, Over zoom for some external talks, project presentations and discussions &lt;br&gt;
&lt;strong&gt;Instructor&lt;/strong&gt;: Prof. Manling Li (Email: &lt;a href=&#34;mailto:manling.li@northwestern.edu&#34;&gt;manling.li@northwestern.edu&lt;/a&gt;)  &lt;br&gt;
&lt;strong&gt;TA&lt;/strong&gt;: Shang Wu (Email: &lt;a href=&#34;mailto:ShangWu2028@u.northwestern.edu&#34;&gt;ShangWu2028@u.northwestern.edu&lt;/a&gt;)  &lt;br&gt;
&lt;strong&gt;Instructor and TA Office Hours&lt;/strong&gt;:  Instructor Monday 11:00am-11:30am in-person, Wednesday 11:00am-11:30am in-person, may change to zoom due to travel schedules. TA office hours are on Monday and Wednesday over zoom (Please contact TA &lt;a href=&#34;mailto:ShangWu2028@u.northwestern.edu&#34;&gt;ShangWu2028@u.northwestern.edu&lt;/a&gt; about it)  &lt;br&gt;
&lt;strong&gt;Course Google Folder&lt;/strong&gt;: announced on Canvas.  &lt;br&gt;
&lt;strong&gt;Assignment Submission&lt;/strong&gt;: on Canvas: &lt;a href=&#34;https://canvas.northwestern.edu/courses/225677&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://canvas.northwestern.edu/courses/225677&lt;/a&gt;   &lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Course Summary&lt;/strong&gt;:
This course will explore the core challenge of reasoning and planning in AI, and how foundation models (such as large language models) build up approaches to problem-solving, decision-making, and automated planning. The course bridges theoretical foundations with cutting-edge applications. Topics include chain-of-thought reasoning for complex problem-solving, agent model (including both digital agent and embodied agent), reasoning under uncertainty, and ethical considerations in automated decision-making. Through a combination of lectures, hands-on laboratories, and project work, students will gain experience in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Understand fundamental principles of reasoning and planning in AI&lt;/li&gt;
&lt;li&gt;Master agent architectures and their implementation using foundation models&lt;/li&gt;
&lt;li&gt;Develop practical skills in designing and implementing web and embodied agents&lt;/li&gt;
&lt;li&gt;Critically evaluate different agent paradigms and their applications&lt;/li&gt;
&lt;li&gt;Design solutions combining classical planning with modern foundation models&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Course Syllabus&lt;/strong&gt;:&lt;/p&gt;
&lt;table style=&#34;border-collapse: collapse; width: 100%; height: 921px;&#34; border=&#34;1&#34;&gt;
    &lt;thead&gt;
        &lt;tr style=&#34;height: 27px;&#34;&gt;
            &lt;th style=&#34;width: 8.547801%; height: 27px;&#34;&gt;Week&lt;/th&gt;
            &lt;th style=&#34;width: 8.286021%; height: 27px;&#34;&gt;Date&lt;/th&gt;
            &lt;th style=&#34;width: 41.215915%; height: 27px;&#34;&gt;Lecture&lt;/th&gt;
            &lt;!-- &lt;th style=&#34;width: 14.643324%; height: 27px;&#34;&gt;Slides&lt;/th&gt;
            &lt;th style=&#34;width: 9.015052%; height: 27px;&#34;&gt;Reading List&lt;/th&gt;
            &lt;th style=&#34;width: 18.160994%; height: 27px;&#34;&gt;Assignment&lt;/th&gt; --&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 111px;&#34; rowspan=&#34;3&#34;&gt;Week 1&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Introduction to Foundation Models and Agent Models&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 53px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 53px;&#34;&gt;01/06&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 53px;&#34;&gt;From Foundation Models to Agent Models: Environment Interaction + Goal-Driven Decision Making&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 53px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;0106-0109.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20866523?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week1.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 53px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.05658&#34;&gt;&lt;span&gt;TidyBot: Personalized Robot Assistance with Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.07207&#34;&gt;&lt;span&gt;Language Models as Zero-Shot Planners: Extracting Actionable Knowledge for Embodied Agents&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2303.03378&#34;&gt;&lt;span&gt;PaLM-E: An embodied multimodal language model&lt;/span&gt;&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.04091&#34;&gt;&lt;span&gt;Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;p&gt;&amp;nbsp;&lt;/p&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2212.04088&#34;&gt;&lt;span&gt;LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;p&gt;&amp;nbsp;&lt;/p&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.08587&#34;&gt;&lt;span&gt;Compositional Foundation Models for Hierarchical Planning&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 53px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/08&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Long Horizon Reasoning and Planning&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;0106-0109.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20866523?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week1.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2401.06209&#34;&gt;&lt;span&gt;Eyes wide shut? exploring the visual shortcomings of multimodal llms&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.19785&#34;&gt;&lt;span&gt;What&#39;s &#34;up&#34; with vision-language models? Investigating their struggle with spatial reasoning&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.14992&#34;&gt;&lt;span&gt;Reasoning with Language Model is Planning with World Model&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 2&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Chain-of-Thought, Tree-of-Thought and Systematic Reasoning&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/13&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Chain-of-Thought, Instruction Tuning, Tree-of-Thought, Graph-of-Thought&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week2-1.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20885387?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week2-1.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2201.11903&#34;&gt;&lt;span&gt;Chain-of-Thought Prompting Elicits Reasoning in Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2109.01652&#34;&gt;&lt;span&gt;​​Finetuned language models are zero-shot learners&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2305.10601&#34;&gt;&lt;span&gt;Tree of Thoughts: Deliberate Problem Solving with Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2308.09687&#34;&gt;&lt;span&gt;Graph of Thoughts: Solving Elaborate Problems with Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/15&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Casual Reasoning&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week2-2.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20892250?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week2-2.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.00050&#34;&gt;&lt;span&gt;Causal Reasoning and Large Language Models: Opening a New Frontier for Causality&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://aclanthology.org/2023.acl-long.509.pdf&#34;&gt;&lt;span&gt;Preserving Commonsense Knowledge from Pre-trained Language Models via Causal Inference&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2205.09712&#34;&gt;&lt;span&gt;CLadder: Assessing Causal Reasoning in Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 3&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Reinforcement Learning&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/20&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;No Class due to holiday&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/22&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Introduction to Reinforcement Learning, RL with feedback&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week3.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20992384?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week3.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2203.02155&#34;&gt;&lt;span&gt;Training language models to follow instructions with human feedback&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2501.12948&#34;&gt;&lt;span&gt;DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://cdn.openai.com/papers/gpt-4.pdf&#34;&gt;&lt;span&gt;GPT-4 Technical Report&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 4&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Introduction to Scaling Law&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/27&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;o1: Time Scaling Law&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;o1-tutorial.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21299385?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week4.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;a href=&#34;https://cdn.openai.com/o1-system-card.pdf&#34;&gt;&lt;span&gt;OpenAI o1 System Card&lt;/span&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;a class=&#34;inline_disabled&#34; href=&#34;https://docs.google.com/spreadsheets/d/1EqWcZ-YvONIXYcYLbrTSaGMsTGJa4SzS/edit?usp=sharing&amp;amp;ouid=117868760614698720089&amp;amp;rtpof=true&amp;amp;sd=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Project Sign Up Sheet&amp;nbsp;&lt;/a&gt;(due on 11:59pm CT, Jan 28 Tuesday)&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;01/29&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Project lightning talks&lt;br /&gt;&lt;br /&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;project 3-min lightning talks (we will follow a random order)&lt;br /&gt;&lt;a class=&#34;inline_disabled&#34; href=&#34;https://docs.google.com/spreadsheets/d/10kpPC4x04QRKye4p37hcP6Y75YSiaSxG/edit?usp=sharing&amp;amp;ouid=117868760614698720089&amp;amp;rtpof=true&amp;amp;sd=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Presentation Voting&lt;/a&gt;&amp;nbsp;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;Initial Project Proposal Due 11:59pm CT Feb 2nd (Sunday), 1-2 page, see &lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;proposalrequirement.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20992446?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;Project Proposal Requirement&lt;/a&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 5&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Knowledge Memorization and Reasoning&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/03&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Continued Project lightning talks&lt;br /&gt;Deepseek-R1&amp;nbsp;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week6.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21092732?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week5-1.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2405.04434&#34;&gt;&lt;span&gt;DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2501.12948&#34;&gt;&lt;span&gt;DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/05&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Information Extraction, Knowledge Graph Representation&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week5_schema_editing.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21299476?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week5_2.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2405.14831&#34;&gt;&lt;span&gt;HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://proceedings.neurips.cc/paper_files/paper/2023/hash/ebd82705f44793b6f9ade5a669d0f0bf-Abstract-Conference.html&#34;&gt;&lt;span&gt;Augmenting Language Models with Long-Term Memory&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.03025&#34;&gt;&lt;span&gt;Retrieval meets Long Context Large Language Models&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 6&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Knowledge-Augmented LLMs&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/10&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Schema Induction, Retrieval-Augmented LMs, Knowledge Editing&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week6-1.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21299379?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;week6.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2206.06520&#34;&gt;&lt;span&gt;Memory-Based Model Editing at Scale&amp;nbsp;&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2305.12740&#34;&gt;&lt;span&gt;Can We Edit Factual Knowledge by In-Context Learning?&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;&lt;a href=&#34;https://arxiv.org/abs/2104.08164&#34;&gt;&lt;span&gt;Editing Factual Knowledge in Language Models&lt;/span&gt; &lt;/a&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/12&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Project Pitch and&lt;span&gt;&amp;nbsp;Discussions&lt;/span&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;span&gt;project report and 10-min presentations&lt;br /&gt;&lt;a class=&#34;inline_disabled&#34; title=&#34;Link&#34; href=&#34;https://docs.google.com/spreadsheets/d/1tf7qGUtBALzVQUJ3dmXN6hJRe96axAEx/edit?usp=sharing&amp;amp;ouid=117868760614698720089&amp;amp;rtpof=true&amp;amp;sd=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Mid-term Voting&lt;/a&gt;&lt;br /&gt;&lt;/span&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;Mid-term Project Report &amp;amp; Presentations,&lt;br /&gt;Due 11:59pm CT Feb 16 (Sunday), 3-4 page, see &lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;proposalrequirement.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/20992446?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;Project Proposal Requirement&lt;/a&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 7&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Advanced Reasoning Topics&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/17&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Knowledge-Driven Reasoning in Embodied Agents (Guest Lecture by Weiyu Liu from Stanford)&lt;br /&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week7_embodied_Weiyu_Liu.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21299366?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;Embodied Reasoning.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/19&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Deepseek R1 Training (Guest Lecture by Weihao Zeng, Junxian He from HKUST)&lt;br /&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;week7_SimpleRL_Slide.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21299493?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;DeepSeek_R1_Training.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 8&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Agent Models - Fundamentals&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/24&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Reasoning in VLMs (Guest Lecture by Ziqiao Ma from UMich)&lt;br /&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;a class=&#34;instructure_file_link instructure_scribd_file inline_disabled&#34; title=&#34;[week8] Language Grounding.pdf&#34; href=&#34;https://limanling.github.io/courses/225677/files/21299528?wrap=1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34; data-canvas-previewable=&#34;false&#34;&gt;Reasoning in VLMs.pdf&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;br /&gt;
                &lt;p&gt;&amp;nbsp;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;02/26&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;First mid-term exam (&lt;span&gt;Proctored by TAs&lt;/span&gt;)&lt;br /&gt;in-person&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;span&gt;three papers&lt;br /&gt;&lt;a href=&#34;https://arxiv.org/pdf/2501.19393&#34;&gt;https://arxiv.org/pdf/2501.19393&lt;/a&gt;&lt;br /&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.08821&#34;&gt;https://arxiv.org/abs/2412.08821&lt;/a&gt;&lt;br /&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.06769&#34;&gt;https://arxiv.org/abs/2412.06769&lt;/a&gt;&lt;/span&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;span&gt;Open-end questions regarding these papers&lt;br /&gt;&lt;/span&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 9&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Advanced Topics on Planning and Reasoning&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;03/03&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;LLM Planning in a MDP formulation&lt;br /&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;03/05&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Search-R1 (RL for search), Simple Test Time Scaling, Large Concept Model, Chain-of-Continunous Thought, Future Directions&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2402.05120&#34;&gt;&lt;span&gt;More Agents Is All You Need&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.02818&#34;&gt;&lt;span&gt;Chain of Agents: Large Language Models Collaborating on Long-Context Tasks&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
                &lt;br /&gt;
                &lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.01014&#34;&gt;&lt;span&gt;Mobile-Agent-v2: Mobile Device Operation Assistant with Effective Navigation via Multi-Agent Collaboration&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
            &lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.547801%; height: 87px;&#34; rowspan=&#34;3&#34;&gt;Week 10&lt;/td&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;&lt;strong&gt;Topic:&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;&lt;strong&gt;Future Directions&lt;/strong&gt;&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;03/10&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Final Project Presentations&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;20-min presentations&lt;br /&gt;&lt;a class=&#34;inline_disabled&#34; href=&#34;https://docs.google.com/spreadsheets/d/1tLVDhWg4zHWPR9QmcnYoPraInj5XqZOU/edit?usp=sharing&amp;amp;ouid=117868760614698720089&amp;amp;rtpof=true&amp;amp;sd=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Presentation&amp;amp;Voting&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;Final Project Report &amp;amp; Presentations&lt;/td&gt; --&gt;
        &lt;/tr&gt;
        &lt;tr style=&#34;height: 29px;&#34;&gt;
            &lt;td style=&#34;width: 8.286021%; height: 29px;&#34;&gt;03/12&lt;/td&gt;
            &lt;td style=&#34;width: 41.215915%; height: 29px;&#34;&gt;Final Project Presentations&lt;/td&gt;
            &lt;!-- &lt;td style=&#34;width: 14.643324%; height: 29px;&#34;&gt;20-min presentations&lt;br /&gt;&lt;a class=&#34;inline_disabled&#34; href=&#34;https://docs.google.com/spreadsheets/d/1tLVDhWg4zHWPR9QmcnYoPraInj5XqZOU/edit?usp=sharing&amp;amp;ouid=117868760614698720089&amp;amp;rtpof=true&amp;amp;sd=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Presentation&amp;amp;Voting&lt;/a&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 9.015052%; height: 29px;&#34;&gt;&lt;/td&gt;
            &lt;td style=&#34;width: 18.160994%; height: 29px;&#34;&gt;Final Project Report &amp;amp; Presentations&lt;/td&gt; --&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Grading&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mid-Term Exams (30pts in total):
&lt;ul&gt;
&lt;li&gt;Each exam will be about open-end questions regarding three papers.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Term Project (70 pts in total, 5pts project proposal, 3pts lightning talk, 12pts mid-term project report, 50pts final project report):
&lt;ul&gt;
&lt;li&gt;The instructor will give 10 topics for the students to choose from. Students are expected to do self-teaming and each team should consist of 3-6 students. Everyone is encouraged to submit papers based on the term projects. Project score will by default be the same for all team members, but some team members can get a higher or lower score than the team score based on individual performance that is assessed in two ways: (1) checking contribution to final deliverables (e.g., Git commits and Final Project Report), and (2) Instructor and TAs&amp;rsquo; opinion from project presentations.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
